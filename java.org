* Basic
  REFS:
  - http://blog.csdn.net/u013551462/article/details/50956090
  - http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html
  - *http://www.tvtv223.com/so/8/default/8.html*

  Java语言（java.long.*）
  Java集合框架（java.util.*）
  Java I/O（java.io.*、java.nio.*.*）
  Java 网络（java.net.*、java.rmi.*、javax.net.*）
  Java 并发（java.util.concurrent.*、java.util.concurrent.*.*）
** final
   根据程序上下文环境，Java关键字final有“这是无法改变的”或者“终态的”含义，它
   可以修饰非抽象类、非抽象类成员方法和变量。你可能出于两种理解而需要阻止改变：
   设计或效率。
   - final类不能被继承，没有子类，final类中的方法默认是final的。
   - final方法不能被子类的方法覆盖，但可以被继承。
   - final成员变量表示常量，只能被赋值一次，赋值后值不再改变。
   - final不能用于修饰构造方法。

   注意：父类的private成员方法是不能被子类方法覆盖的，因此private类型的方法默认
   是final类型的。

   static final用来修饰成员变量和成员方法，可简单理解为“全局常量”！
** transient
   transient是类型修饰符，只能用来修饰字段。在对象序列化的过程中，标记为
   transient的变量不会被序列化。
** static
   static可修饰变量，函数，类，包导入、代码块，根据作用域的不同，呈现不同的效果。

   被static修饰的成员变量和成员方法独立于该类的任何对象。也就是说，它不依赖类特
   定的实例，被类的所有实例共享。只要这个类被加载，Java虚拟机就能根据类名在运行
   时数据区的方法区内定找到他们。因此，static对象可以在它的任何对象创建之前访问，
   无需引用任何对象。
*** 静态内部类
    REFS:
    - http://blog.csdn.net/fgakjfd/article/details/5282646
    - http://blog.csdn.net/vange/article/details/5407625

    字面上看，一个被称为静态嵌套类，一个被称为内部类。从字面的角度解释是这样的：
    什么是嵌套？嵌套就是我跟你没关系，自己可以完全独立存在，但是我就想借你的壳用
    一下，来隐藏一下我自己（真TM猥琐）。什么是内部？内部就是我是你的一部分，我了
    解你，我知道你的全部，没有你就没有我。（所以内部类对象是以外部类对象存在为前
    提的）

    如果你不需要内部类对象与其外围类对象之间有联系，那你可以将内部类声明为static。
    这通常称为嵌套类（nested class）。Static Nested Class是被声明为静态（static）
    的内部类，它可以不依赖于外部类实例被实例化。而通常的内部类需要在外部类实例化
    后才能实例化。想要理解static应用于内部类时的含义，你就必须记住，普通的内部类
    对象隐含地保存了一个引用，指向创建它的外围类对象。然而，当内部类是static的时，
    就不是这样了。嵌套类意味着：
    1. 嵌套类的对象，并不需要其外围类的对象。
    2. 不能从嵌套类的对象中访问非静态的外围类对象。
    3. 静态内部类可以用public,protected,private修饰
    4. 静态内部类中可以定义静态或者非静态的成员
    5. 不能直接访问外部类的非静态成员
    6. 静态内部类不能访问外部类的非静态成员(包括非静态变量和非静态方法)
    7. 静态内部类只能访问外部类的静态成员(包括静态变量和静态方法)
    8. 外部类访问内部类的非静态成员:实例化内部类即可


    在开发过程中，内部类中使用的最多的还是非静态地成员内部类。不过在特定的情况
    下，静态内部类也能够发挥其独特的作用。

    静态内部类在Java语言中是一个很特殊的类，跟普通的静态类以及非静态的内部类都有
    很大的差异。作为程序开发人员，必须要知道他们之间 的差异，并在实际工作中在合
    适的地方采用合适的类。不过总的来说，静态内部类的使用频率并不是很高。但是在有
    一些场合，如果没有这个内部静态类的话，可能会起到事倍功半的反面效果。

    在定义内部类的时候，可以在其前面加上一个权限修饰符static。此时这个内部类就变
    为了静态内部类。不过由于种种的原因，如使用上的限制等 等因素(具体的使用限制，
    笔者在下面的内容中会详细阐述)，在实际工作中用的并不是很多。但是并不是说其没
    有价值。在某些特殊的情况下，少了这个静态内部 类还真是不行。如在进行代码程序
    测试的时候，如果在每一个Java源文件中都设置一个主方法(主方法是某个应用程序的
    入口，必须具有)，那么会出现很多额 外的代码。而且最主要的时这段主程序的代码对
    于Java文件来说，只是一个形式，其本身并不需要这种主方法。但是少了这个主方法又
    是万万不行的。在这种情 况下，就可以将主方法写入到静态内部类中，从而不用为每
    个Java源文件都设置一个类似的主方法。这对于代码测试是非常有用的。在一些中大型
    的应用程序开 发中，则是一个常用的技术手段。为此，这个静态内部类虽然不怎么常
    用，但是程序开发人员还必须要掌握它。也许在某个关键的时刻，其还可以发挥巨大的
    作用也 说不定。

*** 静态导入
    静态导入的语法是：
    - import static 包名.类名.静态成员变量;
    - import static 包名.类名.静态成员函数;

    要使用静态成员（方法和变量）我们必须给出提供这个静态成员的类。

 　　使用静态导入可以使被导入类的静态变量和静态方法在当前类直接可见，使用这些静
    态成员无需再给出他们的类名。

 　　过度地使用静态导入会在一定程度上降低代码的可读性。

** volatile
   REFS:
   - http://www.cnblogs.com/aigongsi/archive/2012/04/01/2429166.html
   - http://www.importnew.com/18126.html

   Java语言是支持多线程的，为了解决线程并发的问题，在语言内部引入了 同步块 和
   volatile 关键字机制。

   一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就
   具备了两层语义：
   1. 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，
      这新值对其他线程来说是立即可见的。
   2. 禁止进行指令重排序。

   这里面就有一个误区了，volatile关键字能保证可见性没有错，但是上面的程序错在没
   能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变
   量的操作的原子性。

   根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作
   都是原子性的。

   用volatile修饰的变量，线程在每次使用变量的时候，都会读取变量修改后的最的值。
   volatile很容易被误用，用来进行原子性操作。

   对于volatile修饰的变量，jvm虚拟机只是保证从主内存加载到线程工作内存的值是最新
   的。用volatile关键字修改之后，还是会存在并发的情况。
** 可变长度参数
   可变长度参数必须作为方法参数列表中的的最后一个参数且方法参数列表中只能有一个
   可变长度参数。
   #+begin_src java
   public static void print(String... strs)
   {
       for (int i = 0; i < strs.length; i++)
       {
           System.out.println(strs[i]);
       }
   }
   #+end_src
** foreach原理
   REFS:
   - https://my.oschina.net/TJALS/blog/842691
   - http://www.cnblogs.com/xrq730/p/4868465.html

   Java提供给了用户大量的语法糖，比如泛型、自动装箱、自动拆箱、foreach循环、变长
   参数、内部类、枚举类、断言（assert）等。

   foreach 语句为数组或对象集合中的每个元素重复一个嵌入语句组。foreach 语句用于
   循环访问集合以获取所需信息，但不应用于更改集合内容以避免产生不可预知的副作用。

   foreach (int a in b) {}

   foreach循环的几个特性:
   1. foreach遍历不能对元素进行赋值操作
   2. 同时只能遍历一个
   3. 遍历的时候，只有当前被遍历的元素可见，其他不可见
   4. 只能正向遍历，不能反向
   5. foreach对ArrayList的遍历是因为其实现了Iterable接口,任何一个集合，无论是JDK
      提供的还是自己写的，只要想使用foreach循环遍历，就必须正确地实现Iterable接口

   在foreach循环中，迭代集合collectionObject的过程如下：
   1. 调用collectionObject.GetEnumerator(),返回一个IEnumerator引用。这个方法可以
      通过IEnumerable接口的实现代码来获得。但这是可选的。
   2. 调用返回的IEnumerator接口的MoveNext()方法。
   3. 如果MoveNext()方法返回true,就使用IEnumerator接口的Current属性获取对象的一
      个引用，用于foreach循环。
   4. 重复前面两步，直到MoveNext()方法返回false为止，此时循环停止。
** 类加载机制
   REFS:
   - http://blog.csdn.net/jintao_ma/article/details/51353453
*** 为什么要使用类加载器？
    Java语言里，类加载都是在程序运行期间完成的，这种策略虽然会令类加载时稍微增加
    一些性能开销，但是会给java应用程序提供高度的灵活性。例如：
    1. 编写一个面向接口的应用程序，可能等到运行时再指定其实现的子类；
    2. 用户可以自定义一个类加载器，让程序在运行时从网络或其他地方加载一个二进制
       流作为程序代码的一部分；(这个是Android插件化，动态安装更新apk的基础)

*** 类加载的过程
    类从被加载到虚拟机内存中开始，到卸载出内存为止，它的生命周期包括了：加载
    (Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化
    (Initialization)、使用(Using)、卸载(Unloading)七个阶段，其中验证、准备、解析
    三个部分统称链接。

    加载(装载)、验证、准备、初始化和卸载这五个阶段顺序是固定的，类的加载过程必须
    按照这种顺序开始，而解析阶段不一定；它在某些情况下可以在初始化之后再开始，这
    是为了运行时动态绑定特性（JIT例如接口只在调用的时候才知道具体实现的是哪个子
    类）。值得注意的是：这些阶段通常都是互相交叉的混合式进行的，通常会在一个阶段
    执行的过程中调用或激活另外一个阶段。

*** 类加载器
    JVM设计者把类加载阶段中的“通过'类全名'来获取定义此类的二进制字节流”这个动
    作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现
    这个动作的代码模块称为“类加载器”。

    1. 类与类加载器

       对于任何一个类，都需要由加载它的类加载器和这个类来确立其在JVM中的唯一性。
       也就是说，两个类来源于同一个Class文件，并且被同一个类加载器加载，这两个类
       才相等。
    2. 双亲委派模型

       从虚拟机的角度来说，只存在两种不同的类加载器：一种是启动类加载器
       （Bootstrap ClassLoader），该类加载器使用C++语言实现，属于虚拟机自身的一
       部分。另外一种就是所有其它的类加载器，这些类加载器是由Java语言实现，独立
       于JVM外部，并且全部继承自抽象类java.lang.ClassLoader。

       从Java开发人员的角度来看，大部分Java程序一般会使用到以下三种系统提供的类
       加载器：

       1. 启动类加载器

       2. 扩展类加载器

       3. 应用类加载器

       4. 自定义类加载器

       类加载器的双亲委派模型（Parent Delegation Model）。该模型要求除了顶层的启
       动类加载器外，其余的类加载器都应当有自己的父类加载器。子类加载器和父类加
       载器不是以继承（Inheritance）的关系来实现，而是通过组合（Composition）关
       系来复用父加载器的代码。


       双亲委派模型的工作过程为：如果一个类加载器收到了类加载的请求，它首先不会
       自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的
       加载器都是如此，因此所有的类加载请求都会传给顶层的启动类加载器，只有当父
       加载器反馈自己无法完成该加载请求（该加载器的搜索范围中没有找到对应的类）
       时，子加载器才会尝试自己去加载。

       使用这种模型来组织类加载器之间的关系的好处是Java类随着它的类加载器一起具
       备了一种带有优先级的层次关系。例如java.lang.Object类，无论哪个类加载器去
       加载该类，最终都是由启动类加载器进行加载，因此Object类在程序的各种类加载
       器环境中都是同一个类。否则的话，如果不使用该模型的话，如果用户自定义一个
       java.lang.Object类且存放在classpath中，那么系统中将会出现多个Object类，应
       用程序也会变得很混乱。

       若要实现自定义类加载器，只需要继承java.lang.ClassLoader 类，并且重写其
       findClass()方法即可。

*** 动态加载Jar && ClassLoader 隔离问题
    ClassLoader 隔离问题：大家觉得一个运行程序中有没有可能同时存在两个包名和类名
    完全一致的类？

    JVM 及 Dalvik 对类唯一的识别是 ClassLoader id + PackageName + ClassName，所
    以一个运行程序中是有可能存在两个包名和类名完全一致的类的。并且如果这两
    个”类”不是由一个 ClassLoader 加载，是无法将一个类的示例强转为另外一个类的，
    这就是 ClassLoader 隔离。

    加载不同 Jar 包中公共类：现在 Host 工程包含了 common.jar, jar1.jar, jar2.jar，
    并且 jar1.jar 和 jar2.jar 都包含了 common.jar，我们通过 ClassLoader 将 jar1,
    jar2 动态加载进来，这样在 Host 中实际是存在三份 common.jar，如下图：
    https://farm4.staticflickr.com/3872/14301963930_2f0f0fe8aa_o.png我们怎么保证
    common.jar 只有一份而不会造成上面3中提到的 ClassLoader 隔离的问题呢，其实很
    简单，在生成 jar1 和 jar2 时把 common.jar 去掉，只保留 host 中一份，以 host
    ClassLoader 为 parentClassLoader 即可。
** Java内存模型，Java内存管理，Java堆和栈，垃圾回收
   REFS:
   - http://www.jcp.org/en/jsr/detail?id=133
   - http://ifeve.com/jmm-faq/

   从1997年以来，人们不断发现Java语言规范的17章定义的Java内存模型中的一些严重的
   缺陷。这些缺陷会导致一些使人迷惑的行为（例如final字段会被观察到值的改变）和破
   坏编译器常见的优化能力。

   Java内存模型是一个雄心勃勃的计划，它是编程语言规范第一次尝试合并一个能够在各
   种处理器架构中为并发提供一致语义的内存模型。不过，定义一个既一致又直观的内存
   模型远比想象要更难。JSR133为Java语言定义了一个新的内存模型，它修复了早期内存
   模型中的缺陷。为了实现JSR133，final和volatile的语义需要重新定义。

   完整的语义见：http://www.cs.umd.edu/users/pugh/java/memoryModel，但是正式的语
   义不是小心翼翼的，它是令人惊讶和清醒的，目的是让人意识到一些看似简单的概念
   （如同步）其实有多复杂。幸运的是，你不需要懂得这些正式语义的细节——JSR133的目
   的是创建一组正式语义，这些正式语义提供了volatile、synchronzied和final如何工作
   的直观框架。

   Java包含了几个语言级别的关键字，包括：volatile, final以及synchronized，目的是
   为了帮助程序员向编译器描述一个程序的并发需求。Java内存模型定义了volatile和
   synchronized的行为，更重要的是保证了同步的java程序在所有的处理器架构下面都能
   正确的运行。

   大部分其他的语言，像C和C++，都没有被设计成直接支持多线程。这些语言对于发生在
   编译器和处理器平台架构的重排序行为的保护机制会严重的依赖于程序中所使用的线程
   库（例如pthreads），编译器，以及代码所运行的平台所提供的保障。

*** 重排序
    在很多情况下，访问一个程序变量（对象实例字段，类静态字段和数组元素）可能会使
    用不同的顺序执行，而不是程序语义所指定的顺序执行。编译器能够自由的以优化的名
    义去改变指令顺序。在特定的环境下，处理器可能会次序颠倒的执行指令。数据可能在
    寄存器，处理器缓冲区和主内存中以不同的次序移动，而不是按照程序指定的顺序。

    例如，如果一个线程写入值到字段a，然后写入值到字段b，而且b的值不依赖于a的值，
    那么，处理器就能够自由的调整它们的执行顺序，而且缓冲区能够在a之前刷新b的值到
    主内存。有许多潜在的重排序的来源，例如编译器，JIT以及缓冲区。

    大部分情况下，一个线程不会关注其他线程正在做什么，但是当它需要关注的时候，这
    时候就需要同步了。

** 同步
   同步有几个方面的作用。最广为人知的就是互斥 ——一次只有一个线程能够获得一个监视
   器，因此，在一个监视器上面同步意味着一旦一个线程进入到监视器保护的同步块中，
   其他的线程都不能进入到同一个监视器保护的块中间，除非第一个线程退出了同步块。


   但是同步的含义比互斥更广。同步保证了一个线程在同步块之前或者在同步块中的一个
   内存写入操作以可预知的方式对其他有相同监视器的线程可见。当我们退出了同步块，
   我们就释放了这个监视器，这个监视器有刷新缓冲区到主内存的效果，因此该线程的写
   入操作能够为其他线程所见。在我们进入一个同步块之前，我们需要获取监视器，监视
   器有使本地处理器缓存失效的功能，因此变量会从主存重新加载，于是其它线程对共享
   变量的修改对当前线程来说就变得可见了。

   对两个线程来说，为了正确建立happens before关系而在相同监视器上面进行同步是非
   常重要的。以下观点是错误的：当线程A在对象X上面同步的时候，所有东西对线程A可见，
   线程B在对象Y上面进行同步的时候，所有东西对线程B也是可见的。释放监视器和获取监
   视器必须匹配（也就是说要在相同的监视器上面完成这两个操作），否则，代码就会存
   在“数据竞争”。

   没有正确同步的代码对于不同的人来说可能会有不同的理解。在Java内存模型这个语义
   环境下，我们谈到“没有正确同步”，我们的意思是：
   - 一个线程中有一个对变量的写操作，
   - 另外一个线程对同一个变量有读操作，
   - 而且写操作和读操作没有通过同步来保证顺序。

   当这些规则被违反的时候，我们就说在这个变量上有一个“数据竞争”(data race)。一
   个有数据竞争的程序就是一个没有正确同步的程序。
** 日志
   8.1 jdk自带的logging、log4j、log4j2、logback
   8.2 门面commons-logging、slf4j
   8.3 上述6种混战时的日志转换
** Callable, Runnable
   Callable接口类似于Runnable，从名字就可以看出来了，但是Runnable不会返回结果，
   并且无法抛出返回结果的异常，而Callable功能更强大一些，被线程执行后，可以返回
   值，这个返回值可以被Future拿到，也就是说，Future可以拿到异步执行任务的返回值，

   FutureTask实现了两个接口，Runnable和Future，所以它既可以作为Runnable被线程执
   行，又可以作为Future得到Callable的返回值，那么这个组合的使用有什么好处呢？假
   设有一个很耗时的返回值需要计算，并且这个返回值不是立刻需要的话，那么就可以使
   用这个组合，用另一个线程去计算返回值，而当前线程在使用这个返回值之前可以做其
   它的操作，等到需要这个返回值时，再通过Future得到，岂不美哉！

   另一种方式使用Callable和Future，通过ExecutorService的submit方法执行Callable，
   并返回Future。代码是不是简化了很多，ExecutorService继承自Executor，它的目的是
   为我们管理Thread对象，从而简化并发编程，Executor使我们无需显示的去管理线程的
   生命周期，是JDK 5之后启动任务的首选方式。
** 线程池
   REFS:
   - http://blog.csdn.net/ghsau/article/details/7443324
   - http://www.cnblogs.com/nullzx/p/5175574.html
   - http://www.cnblogs.com/aaron911/p/6213808.html

*** 工作原理
    线程池的工作模型主要两部分组成，一部分是运行Runnable的Thread对象，另一部分就
    是阻塞队列。

    由线程池创建的Thread对象其内部的run方法会通过阻塞队列的take方法获取一个
    Runnable对象，然后执行这个Runnable对象的run方法（即，在Thread的run方法中调用
    Runnable对象的run方法）。当Runnable对象的run方法执行完毕以后，Thread中的run
    方法又循环的从阻塞队列中获取下一个Runnable对象继续执行。这样就实现了Thread对
    象的重复利用，也就减少了创建线程和销毁线程所消耗的资源。

    当需要向线程池提交任务时会调用阻塞队列的offer方法向队列的尾部添加任务。提交
    的任务实际上就是是Runnable对象或Callable对象。

    上述仅仅是最简略的线程池工作模型，但体现了线程池的核心思想，而至于线程池中线
    程的动态的创建和自行销毁、动态调整实际工作的线程数、阻塞队列的排队策略以及队
    列的长度等等细节问题会在本博客中“线程池 ThreadPoolExecutor、Executors源代码
    分析”的文章中详细介绍。
*** 四种不同的线程池
**** FixedThreadPool
     一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作
     线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。

     FixedThreadPool是一个典型且优秀的线程池，它具有线程池提高程序效率和节省创建
     线程时所耗的开销的优点。但是，在线程池空闲时，即线程池中没有可运行任务时，
     它不会释放工作线程，还会占用一定的系统资源。

**** Cached
     一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回
     收，则新建线程。

     这种类型的线程池特点是：
     - 工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE),
       这样可灵活的往线程池中添加线程。
     - 如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1
       分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重
       新创建一个工作线程。
     - 在使用CachedThreadPool时，一定要注意控制任务的数量，否则，由于大量线程同
       时运行，很有会造成系统瘫痪。

**** SingleThreadExecutor
     创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，它只会用唯
     一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。
     如果这个线程异常结束，会有另一个取代它，保证顺序执行。单工作线程最大的特点
     是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。

**** ScheduleThreadPool
     创建一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性
     任务执行。
** CAS
*** CAS指令
    CAS指的是现代 CPU 广泛支持的一种对内存中的共享数据进行操作的一种特殊指令。这
    个指令会对内存中的共享数据做原子的读写操作。简单介绍一下这个指令的操作过程：
    首先，CPU 会将内存中将要被更改的数据与期望的值做比较。然后，当这两个值相等时，
    CPU 才会将内存中的数值替换为新的值。否则便不做操作。最后，CPU 会将旧的数值返
    回。这一系列的操作是原子的。它们虽然看似复杂，但却是 Java 5 并发机制优于原有
    锁机制的根本。简单来说，CAS 的含义是“我认为原有的值应该是什么，如果是，则将
    原有的值更新为新值，否则不做修改，并告诉我原来的值是多少”。（这段描述引自
    《Java并发编程实践》）简单的来说，CAS有3个操作数，内存值V，旧的预期值A，要修
    改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则返回V。这是
    一种乐观锁的思路，它相信在它修改之前，没有其它线程去修改它；而Synchronized是
    一种悲观锁，它认为在它修改之前，一定会有其它线程去修改它，悲观锁效率很低。
*** CAS的目的
    利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法。其它原子操作都是利用类
    似的特性完成的。而整个J.U.C都是建立在CAS之上的，因此对于synchronized阻塞算法，
    J.U.C在性能上有了很大的提升。
*** CAS存在的问题
    CAS虽然很高效的解决原子操作，但是CAS仍然存在三大问题。ABA问题，循环时间长开
    销大和只能保证一个共享变量的原子操作

    1. ABA问题。因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变
       化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查
       时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用
       版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B
       －A 就会变成1A-2B－3A。

    从Java1.5开始JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。
    这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标
    志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定
    的更新值。

    关于ABA问题参考文档:
    http://blog.hesey.NET/2011/09/resolve-aba-by-atomicstampedreference.html

    2. 循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。
       如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个
       作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行
       资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它
       可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU
       流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

   3. 只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循
      环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作
      的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并
      成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS
      来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子
      性，你可以把多个变量放在一个对象里来进行CAS操作。

** Lock 与 synchronized 的区别
   REFS:
   1. http://www.cnblogs.com/nsw2018/p/5821738.html
   2. http://www.cnblogs.com/benshan/p/3551987.html


   1. synchronized是在JVM层面上实现的，不但可通过一些监控工具监控 synchronized 的
      锁定，而且代码执行出现异常时，JVM会自动释放锁定。但Lock不行，其是通过代码实
      现的，要保证锁一定会被释放，就必须将unLock放到 finally {} 中。
   2. 在并发量比较小的情况下，使用synchronized是个不错的选择，但是在并发量比较高
      的情况下，其性能下降很严重，此时ReentrantLock是个不错的方案。
   3. ReentrantLock 拥有Synchronized相同的并发性和内存语义，此外还多了 锁投票，定
      时锁等候和中断锁等。在资源竞争不激烈的情形下，性能稍微比synchronized差点点。
      但是当同步非常激烈的时候，synchronized的性能一下子能下降好几十倍。而
      ReentrantLock确还能维持常态。


   我们写同步的时候，优先考虑synchronized，如果有特殊需要，再进一步优化。
   ReentrantLock和Atomic如果用的不好，不仅不能提高性能，还可能带来灾难。

*** 使用
    需要对一个方法进行同步，那么只需在方法的签名添加一个synchronized关键字。
   #+begin_src java
   // 未同步的方法
   public void test() {}

   // 同步的方法
   pubilc synchronized void test() {}

   public void test() {
      synchronized(obj) {
      // 当 obj == this 时， 等同于 同步的方法
           System.out.println("===");
      }
   }
   #+end_src

   使用synchronized代码块，可以只对需要同步的代码进行同步，这样可以大大的提高效率。

   使用synchronized 代码块相比方法有两点优势：
   1. 可以只对需要同步的使用
   2. 与wait()/notify()/nitifyAll()一起使用时，比较方便

** 理解Java中的弱引用
   我面试了一些求职Java高级开发工程师的应聘者。我常常会面试他们说，“你能给我介绍
   一些Java中得弱引用吗？”，如果面试者这样说，“嗯，是不是垃圾回收有关的？”，我
   就会基本满意了，我并不期待回答是一篇诘究本末的论文描述
*** 强引用
*** 软引用
*** 弱引用
*** 虚引用

** 深入理解Hash表
   REFS:
   - http://www.cnblogs.com/chinajava/p/5808416.html

   Java 的长处在于当哈希函数不合理导致链表过长时，会使用红黑树来保证插入和查找的
   效率。缺点是当哈希表比较大时，如果扩容会导致瞬时效率降低。

   Redis 通过增量式扩容解决了这个缺点，同时拉链法的实现(放在链表头部)值得我们学
   习。Redis 还提供了一个经过严格测试，表现良好的默认哈希函数，避免了链表过长的
   问题。

   Objective-C 的实现和 Java 比较类似，当我们需要重写 isEqual() 方法时，还需要重
   写 hash 方法。这两种语言并没有提供一个通用的、默认的哈希函数，主要是考虑到
   isEqual() 方法可能会被重写，两个内存数据不同的对象可能在语义上被认为是相同的。
   如果使用默认的哈希函数就会得到不同的哈希值，这两个对象就会同时被添加到 NSSet
   集合中，这可能违背我们的期望结果。

   根据我的了解，Redis 并不支持重写哈希方法，难道 Redis 就没有考虑到这个问题么？
   实际上还要从 Redis 的定位说起。由于它是一个高效的，Key-Value 存储系统，它的
   key 并不会是一个对象，而是一个用来唯一确定对象的标记。

   一般情况下，如果要存储某个用户的信息，key 的值可能是这样: user:100001。Redis
   只关心 key 的内存中的数据，因此只要是可以用二进制表示的内容都可以作为 key，比
   如一张图片。Redis 支持的数据结构包括哈希表和集合(Set)，但是其中的数据类型只能
   是字符串。因此 Redis 并不存在对象等同性的考虑，也就可以提供默认的哈希函数了。

   Redis、Java、Objective-C 之间的异同再次证明了一点:没有完美的架构，只有满足需
   求的架构。

   回到文章开头的问题中来，有两个字典，分别存有 100 条数据和 10000 条数据，如果用一个不存在的 key 去查找数据，在哪个字典中速度更快？

   完整的答案是:

   在 Redis 中，得益于自动扩容和默认哈希函数，两者查找速度一样快。在 Java 和
   Objective-C 中，如果哈希函数不合理，返回值过于集中，会导致大字典更慢。Java 由
   于存在链表和红黑树互换机制，搜索时间呈对数级增长，而非线性增长。在理想的哈希
   函数下，无论字典多大，搜索速度都是一样快。

   最后，整理了一下本文提到的知识点，希望大家读完文章后对以下问题有比较清楚透彻
   的理解:
   - 哈希表中负载因子的概念
   - 哈希表扩容的过程，以及对查找性能的影响
   - 哈希表扩容速度的优化，拉链法插入新元素的优化，链表过长时的优化
   - 不同语言、使用场景下的取舍

** Java代理
*** 代理模式简述
    代理模式是常用的Java设计模式，他的特征是代理类与委托类有同样的接口，代理类主
    要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。
    代理类与委托类之间通常会存在关联关系，一个代理类的对象与一个委托类的对象关联，
    代理类的对象本身并不真正实现服务，而是通过调用委托类的对象的相关方法，来提供
    特定的服务。
*** 静态代理
    由程序员创建或特定工具自动生成源代码，再对其编译。在程序运行前，代理类
    的.class文件就已经存在了。
    #+begin_src java
    public interface Count() {
        public void query();
        public void update();
    }

    public class CountImpl implements Count {
        @Override
        public void query() {}
        @Override
        public void update() {}
    }

    public class CountProxy implements Count {
        private CountImpl countImpl;
        public CountProxy(CountImpl countImpl) {
            this.countImpl = countImpl;
        }

        @Override
        public void query() {
            #before()
            countImpl.query()
            #after()
        }
    }

    #+end_src

*** JDK动态代理
    特点：只能对实现了接口的类生产代理，不能针对类

*** CGLIB动态代理
    JDK的动态代理机制只能代理实现了接口的类，而不能实现接口的类就不能实现JDK的动
    态代理，cglib是针对类来实现代理的，他的原理是对指定的目标类生成一个子类，并
    覆盖其中方法实现增强，但因为采用的是继承，所以不能对final修饰的类进行代理。

    CGLIB是一个强大的高性能的代码生成包。被广泛的许多AOP框架使用，如Spring的AOP
    和dynaop，为他们提供方法的interceptor(拦截)，最流行的是OR Mapping工具
    hibernate也是使用CGLIB来代理单端的single-ended（多对一和一对一）关联（对集合
    的延迟抓取是采用其他机制实现）。EsayMock和jMock是通过模仿（moke）对象来测试
    java代码的包。他们都是通过使用CGLIB来为那些没有接口的类创建模仿（moke）对象。
** 线程池的原理及实现
   多线程技术主要解决处理器单元内多个线程执行的问题，它可以显著减少处理器单元的
   闲置时间，增加处理器单元的吞吐能力。

   假设一个服务器完成一项任务所需时间为：T1 创建线程时间，T2 在线程中执行任务的
   时间，T3 销毁线程时间。如果：T1 + T3 远大于 T2，则可以采用线程池，以提高服务
   器性能。

   一个线程池包括以下四个基本组成部分：
   1. 线程池管理器（ThreadPool）：用于创建并管理线程池，包括 创建线程池，销毁线程池，添加新任务；
   2. 工作线程（PoolWorker）：线程池中线程，在没有任务时处于等待状态，可以循环的执行任务；
   3. 任务接口（Task）：每个任务必须实现的接口，以供工作线程调度任务的执行，它主要规定了任务的入口，任务执行完后的收尾工作，任务的执行状态等；
   4. 任务队列（taskQueue）：用于存放没有处理的任务。提供一种缓冲机制。

   线程池技术正是关注如何缩短或调整T1,T3时间的技术，从而提高服务器程序性能的。它
   把T1，T3分别安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在
   服务器程序处理客户请求时，不会有T1，T3的开销了。

   线程池不仅调整T1,T3产生的时间段，而且它还显著减少了创建线程的数目。
*** java提供的线程池
    REFS:
    - http://www.jianshu.com/p/87bff5cc8d8c
*** ConcurrentHashMap
    REFS:
    - http://www.importnew.com/22007.html
**** HashMap与ConcurrentHashMap的区别
     REFS:
     - http://blog.csdn.net/xuefeng0707/article/details/40834595
     - http://ifeve.com/concurrenthashmap/


     ConcurrentHashMap具体是怎么实现线程安全的呢，肯定不可能是每个方法加synchronized，那样就变成了HashTable。

     从ConcurrentHashMap代码中可以看出，它引入了一个“分段锁”的概念，具体可以理
     解为把一个大的Map拆分成N个小的HashTable，根据key.hashCode()来决定把key放到
     哪个HashTable中。

     在ConcurrentHashMap中，就是把Map分成了N个Segment，put和get的时候，都是现根
     据key.hashCode()算出放到哪个Segment中。

     通过把整个Map分为N个Segment（类似HashTable），可以提供相同的线程安全，但是
     效率提升N倍，默认提升16倍。

** Java集合类
   REFS:
   - http://blog.csdn.net/HHcoco/article/details/53117525
   - http://www.importnew.com/20894.html
   - http://www.cnblogs.com/paddix/p/5539326.html

   Java中的集合包含多种数据结构，如链表、队列、哈希表等。从类的继承结构来说，可
   以分为两大类，一类是继承自Collection接口，这类集合包含List、Set和Queue等集合
   类。另一类是继承自Map接口，这主要包含了哈希表相关的集合类。
*** Collection
**** List
     用的比较多List包括ArrayList和LinkedList，这两者的区别也很明显，从其名称上就
     可以看出。ArrayList的底层的通过数组实现，所以其随机访问的速度比较快，但是对
     于需要频繁的增删的情况，效率就比较低了。而对于LinkedList，底层通过链表来实现，
     所以增删操作比较容易完成，但是对于随机访问的效率比较低。
**** Set
     Set与List的主要区别是Set是不允许元素重复的，而List则可以允许元素重复的。判断
     元素的重复需要根据对象的hash方法和equals方法来决定。这也是我们通常要为集合中
     的元素类重写hashCode方法和equals方法的原因。

     HashSet和LinkedHashSet的区别在于后者可以保证元素插入集合的元素顺序与输出顺序
     保持一致。而TresSet的区别在于其排序是按照Comparator来进行排序的，默认情况下
     按照字符的自然顺序进行升序排列。
**** Queue
     一般可以直接使用LinkedList完成，从上述类图也可以看出，LinkedList继承自Deque，
     所以LinkedList具有双端队列的功能。PriorityQueue的特点是为每个元素提供一个优
     先级，优先级高的元素会优先出队列。
*** Map
    Map类型的集合最大的优点在于其查找效率比较高，理想情况下可以实现O(1)的时间复杂
    度。Map中最常用的是HashMap，LinkedHashMap与HashMap的区别在于前者能够保证插入
    集合的元素顺序与输出顺序一致。这两者与TreeMap的区别在于TreeMap是根据键值进行
    排序的，当然其底层的实现也有本质的区别，如HashMap底层是一个哈希表，而TreeMap
    的底层数据结构是一棵树。

** ThreadLocal
   REFS:
   - http://www.iteye.com/topic/103804

   ThreadLocal不是用来解决对象共享访问问题的，而主要是提供了保持对象的方法和避免
   参数传递的方便的对象访问方式。归纳了两点：
   1. 每个线程中都有一个自己的ThreadLocalMap类对象，可以将线程自己的对象保持到其
      中，各管各的，线程可以正确的访问到自己的对象。
   2. 将一个共用的ThreadLocal静态实例作为key，将不同对象的引用保存到不同线程的
      ThreadLocalMap中，然后在线程执行的各处通过这个静态ThreadLocal实例的get()方
      法取得自己线程保存的那个对象，避免了将这个对象作为参数传递的麻烦。

   当然如果要把本来线程共享的对象通过ThreadLocal.set()放到线程中也可以，可以实现
   避免参数传递的访问方式，但是要注意get()到的是那同一个共享对象，并发访问问题要
   靠其他手段来解决。但一般来说线程共享的对象通过设置为某类的静态变量就可以实现
   方便的访问了，似乎没必要放到线程中。

   ThreadLocal的应用场合，我觉得最适合的是按线程多实例（每个线程对应一个实例）的
   对象的访问，并且这个对象很多地方都要用到。

** Semaphore（信号量）
   用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共
   资源。很多年以来，我都觉得从字面上很难理解Semaphore所表达的含义，只能把它比作
   是控制流量的红绿灯，比如XX马路要限制流量，只允许同时有一百辆车在这条路上行使，
   其他的都必须在路口等待，所以前一百辆车会看到绿灯，可以开进这条马路，后面的车
   会看到红灯，不能驶入XX马路，但是如果前一百辆中有五辆车已经离开了XX马路，那么
   后面就允许有5辆车驶入马路，这个例子里说的车就是线程，驶入马路就表示线程在执行，
   离开马路就表示线程执行完成，看见红灯就表示线程被阻塞，不能执行。

   应用场景

   Semaphore可以用于做流量控制，特别公用资源有限的应用场景，比如数据库连接。假如
   有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个
   线程并发的读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只
   有10个，这时我们必须控制只有十个线程同时获取数据库连接保存数据，否则会报错无
   法获取数据库连接。这个时候，我们就可以使用Semaphore来做流控
** CountDownLatch
   Java并发API提供这样的类，它允许1个或者多个线程一直等待，直到一组操作执行完成。
   这个类就是CountDownLatch类。它初始一个整数值，此值是线程将要等待的操作数。当
   某个线程为了想要执行这些操作而等待时， 它要使用 await()方法。此方法让线程进入
   休眠直到操作完成。 当某个操作结束，它使用countDown() 方法来减少CountDownLatch
   类的内部计数器。当计数器到达0时，这个类会唤醒全部使用await() 方法休眠的线程们。
** CyclicBarrier
   和CountDownLatch一样，都是关于线程的计数器。
   - CyclicBarrier初始化时规定一个数目，然后计算调用了CyclicBarrier.await()进入
     等待的线程数。当线程数达到了这个数目时，所有进入等待状态的线程被唤醒并继续。
   - CyclicBarrier就象它名字的意思一样，可看成是个障碍， 所有的线程必须到齐后才
     能一起通过这个障碍。
   - CyclicBarrier初始时还可带一个Runnable的参数， 此Runnable任务在CyclicBarrier
     的数目达到后，所有其它线程被唤醒前被执行
** Java并发之CountDownLatch、CyclicBarrier和Semaphore
   这次说一下 JUC 中的同步器三个主要的成员：CountDownLatch、CyclicBarrier 和
   Semaphore（不知道有没有初学者觉得这三个的名字不太好记）。这三个是 JUC 中较为
   常用的同步器，通过它们可以方便地实现很多线程之间协作的功能。

   CountDownLatch 是能使一组线程等另一组线程都跑完了再继续跑；CyclicBarrier 能够
   使一组线程在一个时间点上达到同步，可以是一起开始执行全部任务或者一部分任务。

   CountDownLatch 的作用和 Thread.join() 方法类似，可用于一组线程和另外一组线程
   的协作。例如，主线程在做一项工作之前需要一系列的准备工作，只有这些准备工作都
   完成，主线程才能继续它的工作。这些准备工作彼此独立，所以可以并发执行以提高速
   度。在这个场景下就可以使用 CountDownLatch 协调线程之间的调度了。在直接创建线
   程的年代（Java 5.0 之前），我们可以使用 Thread.join()。在 JUC 出现后，因为线
   程池中的线程不能直接被引用，所以就必须使用 CountDownLatch 了。

   CyclicBarrier 翻译过来叫循环栅栏、循环障碍什么的（还是有点别扭的。所以还是别
   翻译了，只可意会不可言传啊）。它主要的方法就是一个：await()。await() 方法没被
   调用一次，计数便会减少1，并阻塞住当前线程。当计数减至0时，阻塞解除，所有在此
   CyclicBarrier 上面阻塞的线程开始运行。在这之后，如果再次调用 await() 方法，计
   数就又会变成 N-1，新一轮重新开始，这便是 Cyclic 的含义所在。
*** CyclicBarrier 和 CountDownLatch 在用法上的不同
    CountDownLatch 适用于一组线程和另一个主线程之间的工作协作。一个主线程等待一
    组工作线程的任务完毕才继续它的执行是使用 CountDownLatch 的主要场景；
    CyclicBarrier 用于一组或几组线程，比如一组线程需要在一个时间点上达成一致，例
    如同时开始一个工作。另外，CyclicBarrier 的循环特性和构造函数所接受的
    Runnable 参数也是 CountDownLatch 所不具备的。
** Callable, Runnable 和 Future接口
   Callable是类似于Runnable的接口，实现Callable接口的类和实现Runnable的类都是可
   被其它线程执行的任务。

   Callable和Runnable有几点不同：
   1. Callable规定的方法是call()，而Runnable规定的方法是run().
   2. Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。
   3. call()方法可抛出异常，而run()方法是不能抛出异常的。
   4. 运行Callable任务可拿到一个Future对象，

   Future 表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，
   并检索计算的结果。

   通过Future对象可了解任务执行情况，可取消任务的执行，还可获取任务执行的结果。
** FutureTask
   实现了Runnable和Future，所以兼顾两者优点。既可以使用ExecutorService，也可以使
   用Thread。
** fork-join框架
   fork操作的作用是把一个大的问题划分成若干个较小的问题。在这个划分过程一般是递
   归进行的。直到可以直接进行计算。需要恰当地选取子问题的大小。太大的子问题不利
   于通过并行方式来提高性能，而太小的子问题则会带来较大的额外开销。每个子问题计
   算完成后，可以得到关于整个问题的部分解。join操作的作用是把这些分解手机组织起
   来，得到完整解。

   在fork/join框架中，若某个子问题由于等待另一个子问题的完成而无法继续执行。那么
   处理该子问题的线程会主动寻找其他尚未运行完成的子问题来执行。这种方式减少了线
   程的等待时间，提高了性能。子问题中应该避免使用synchronized关键词或其他方式方
   式的同步。也不应该是一阻塞IO或过多的访问共享变量。在理想情况下，每个子问题的
   实现中都应该只进行CPU相关的计算，并且只适用每个问题的内部对象。唯一的同步应该
   只发生在子问题和创建它的父问题之间。

   一个fork/join框架之下的任务由ForkJoinTask类表示。ForkJoinTask实现了Future接口，
   可以按照Future接口的方式来使用。在ForkJoinTask类中之重要的两个方法fork和join。
   fork方法用以一部方式启动任务的执行，join方法则等待任务完成并返回指向结果。在
   创建自己的任务是，最好不要直接继承自ForkJoinTask类，而要继承自ForkJoinTask类
   的子类RecurisiveTask或RecurisiveAction类。两种的区别在于RecurisiveTask类表示
   的任务可以返回结果，而RecurisiveAction类不行。

   ForkJoinTask在执行的时候可能会抛出异常，但是没办法在主线程里直接捕获异常，所
   以ForkJoinTask提供了isCompletedAbnormally()方法来检查任务是否已经抛出异常或已
   经被取消了，并且可以通过ForkJoinTask的getException方法获取异常。

* 网络编程知识
** HTTPS的实现原理
   HTTPS其实是有两部分组成：HTTP + SSL / TLS，也就是在HTTP上又加了一层处理加密信
   息的模块。服务端和客户端的信息传输都会通过TLS进行加密，所以传输的数据都是加密
   后的数据。

   | Client                   | message                       | Server                   |
   |                          | -> https://www.baidu.com      |                          |
   |                          |                               | crt private + crt public |
   |                          | resp with crt public <-       |                          |
   | validate crt             |                               |                          |
   | generate random key      |                               |                          |
   | crypt with crt           | -> tranfer crypted randon key |                          |
   |                          |                               | decrypt with private crt |
   |                          |                               | get key                  |
   |                          |                               | crypt contend with key   |
   |                          | resp crypted content <-       |                          |
   | decrypt content with key |                               |                          |

   SSL介于应用层和TCP层之间。应用层数据不再直接传递给传输层，而是传递给SSL层，
   SSL层对从应用层收到的数据进行加密，并增加自己的SSL头。

   RSA性能是非常低的，原因在于寻找大素数、大数计算、数据分割需要耗费很多的CPU周
   期，所以一般的HTTPS连接只在第一次握手时使用非对称加密，通过握手交换对称加密密
   钥，在之后的通信走对称加密。

   HTTPS在传输数据之前需要客户端（浏览器）与服务端（网站）之间进行一次握手，在握
   手过程中将确立双方加密传输数据的密码信息。TLS/SSL协议不仅仅是一套加密传输的协
   议，更是一件经过艺术家精心设计的艺术品，TLS/SSL中使用了非对称加密，对称加密以
   及HASH算法。

   握手过程的具体描述如下：
   1. 浏览器将自己支持的一套加密规则发送给网站。
   2. 网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏
      览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。
   3. 浏览器获得网站证书之后浏览器要做以下工作：
      1. 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正
         在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，
         否则会给出证书不受信的提示。
      2. 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的
         密码，并用证书中提供的公钥加密。
      3. 使用约定好的HASH算法计算握手消息，并使用生成的随机数对消息进行加密，最
         后将之前生成的所有信息发送给网站。
   4. 网站接收浏览器发来的数据之后要做以下的操作：
      1. 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并
         验证HASH是否与浏览器发来的一致。
      2. 使用密码加密一段握手消息，发送给浏览器。

5.浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。
** 表单提交中get和post方式的区别
   - GET是从服务器上获取数据，POST是向服务器传送数据。
   - GET是把参数数据队列加到提交表单的ACTION属性所指的URL中，值和表单内各个字段
     一一对应，在URL中可以看到。POST是通过HTTP POST机制，将表单内各个字段与其内
     容放置在HTML HEADER内一起传送到ACTION属性所指的URL地址。用户看不到这个过程。
   - 对于GET方式，服务器端用Request.QueryString获取变量的值，对于POST方式，服务
     器端用Request.Form获取提交的数据。
   - GET传送的数据量较小，不能大于2KB（这主要是因为受URL长度限制）。POST传送的数
     据量较大，一般被默认为不受限制。但理论上，限制取决于服务器的处理能力。
   - GET安全性较低，POST安全性较高。因为GET在传输过程，数据被放在请求的URL中，而
     如今现有的很多服务器、代理服务器或者用户代理都会将请求URL记录到日志文件中，
     然后放在某个地方，这样就可能会有一些隐私的信息被第三方看到。另外，用户也可
     以在浏览器上直接看到提交的数据，一些系统内部消息将会一同显示在用户面前。
     POST的所有操作对用户来说都是不可见的。
** Java RMI，Socket，HttpClient
** NIO模块以及对应的Netty和Mina、thrift源码
   4.1 TCP握手和断开及有限状态机
   4.2 backlog
   4.3 BIO NIO
   4.4 阻塞/非阻塞的区别、同步/异步的区别
   4.5 阻塞IO、非阻塞IO、多路复用IO、异步IO
   4.6 Reactor线程模型
   4.7 jdk的poll、epoll与底层poll、epoll的对接实现
   4.8 Netty自己的epoll实现
   4.9 内核层poll、epoll的大致实现
   4.10 epoll的边缘触发和水平触发
   4.11 Netty的EventLoopGroup设计
   4.12 Netty的ByteBuf设计
   4.13 Netty的ChannelHandler
   4.13 Netty的零拷贝
   4.14 Netty的线程模型，特别是与业务线程以及资源释放方面的理解
** 用Java写一个简单的静态文件的HTTP服务器
   - 实现客户端缓存功能，支持返回304
   - 实现可并发下载一个文件
   - 使用线程池处理客户端请求
   - 使用nio处理客户端请求
   - 支持简单的rewrite规则
   - 上述功能在实现的时候需要满足“开闭原则”
** 了解nginx和apache服务器的特性并搭建一个对应的服务器
** Java NIO
   REFS:
   - https://zhuanlan.zhihu.com/p/23488863
   - http://ifeve.com/overview/
   - http://blog.chinaunix.net/uid-11572501-id-2868654.html

*** 基础知识
    NIO（Non-blocking I/O，在Java领域，也称为New I/O），是一种同步非阻塞的I/O模
    型，也是I/O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高
    并发与大量连接、I/O处理问题的有效方式。

    那么NIO的本质是什么样的呢？它是怎样与事件模型结合来解放线程、提高系统吞吐的
    呢？

**** 传统BIO模型分析
     BIO，即同步阻塞I/O处理（也就是BIO，Blocking I/O）。

     经典的每连接每线程的模型，之所以使用多线程，主要原因在于socket.accept()、
     socket.read()、socket.write()三个主要函数都是同步阻塞的，当一个连接在处理
     I/O的时候，系统是阻塞的，如果是单线程的话必然就挂死在那里；但CPU是被释放出
     来的，开启多线程，就可以让CPU去处理更多的事情。其实这也是所有使用多线程的本
     质：
     - 利用多核。
     - 当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。

     现在的多线程一般都使用线程池，可以让线程的创建和回收成本相对较低。在活动连
     接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个
     连接专注于自己的I/O并且编程模型简单，也不用过多考虑系统的过载、限流等问题。
     线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。

     不过，这个模型最本质的问题在于，严重依赖于线程。但线程是很"贵"的资源，主要
     表现在:
     1. 线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进
        程。创建和销毁都是重量级的系统函数。
     2. 线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系
        统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。
     3. 线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，
        然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执
        行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过
        20%以上)，导致系统几乎陷入不可用的状态。
     4. 容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线
        程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激
        活大量阻塞线程从而使系统负载压力过大。

     当面对十万甚至百万级连接的时候，传统的BIO模型是无能为力的。随着移动端应用的
     兴起和各种网络游戏的盛行，百万级长连接日趋普遍，此时，必然需要一种更高效的
     I/O处理模型。

**** 常见I/O模型对比

     所有的系统I/O都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统
     可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。

     需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻
     塞是使用CPU的，真正在"干活"，而且这个过程非常快，属于memory copy，带宽通常
     在1GB/s级别以上，可以理解为基本不耗时。

     以socket.read()为例子：

     传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，
     直到收到数据，返回读到的数据。

     对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；
     反之则直接返回0，永远不会阻塞。

     最新的AIO(Async I/O)里面会更进一步：不但等待就绪是非阻塞的，就连数据从网卡
     到内存的过程也是异步的。

     换句话说，BIO里用户最关心“我要读”，NIO里用户最关心"我可以读了"，在AIO模型
     里用户更需要关注的是“读完了”。

     NIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是
     非阻塞的，真正的I/O操作是同步阻塞的（消耗CPU但性能非常高）。

     NIO给我们带来了些什么：
     - 事件驱动模型
     - 避免多线程
     - 单线程处理多任务
     - 非阻塞I/O，I/O读写不再阻塞，而是返回0
     - 基于block的传输，通常比基于流的传输更高效
     - 更高级的IO函数，zero-copy
     - IO多路复用大大提高了Java网络应用的可伸缩性和实用性

*** NIO存在的问题
    使用NIO != 高性能，当连接数<1000，并发程度不高或者局域网环境下NIO并没有显著
    的性能优势。

    NIO并没有完全屏蔽平台差异，它仍然是基于各个操作系统的I/O系统实现的，差异仍然
    存在。使用NIO做网络编程构建事件驱动模型并不容易，陷阱重重。

    推荐大家使用成熟的NIO框架，如Netty，MINA等。解决了很多NIO的陷阱，并屏蔽了操
    作系统的差异，有较好的性能和编程模型。

*** 开发基于NIO实现高效和高可扩展服务，还有哪些构架方面的问题需要考虑呢？
    REFS:
    - http://www.360doc.com/content/16/0524/22/16915_562024315.shtml

    NIO构架中比较需要经验和比较复杂的主要是2点：
    1. 基于提高的性能的线程池设计；
    2. 基于网络通讯量的通讯完整性校验的构架。

**** 基于提高的性能的线程池设计
     既然有一个单独处理逻辑业务的线程池，这个线程池的大小应该由你的业务来决定。
     对于高效服务器来说，这个线程池大小会对你的服务性能产生很大的影响。设置多少
     合适呢？

     这里真的有很多情况需要考虑，换句话说，这里水很深。我只能根据自己的经验举几
     个例子。真正到了运营系统上，一边测试一边调整一边总结吧。

     假设消息解析用时5毫秒，数据库操作用时20毫秒，其他逻辑处理用时20毫秒，那么整
     个业务处理用时45毫秒。因为数据库操作主要是IO读写操作，为使CPU得到最大程度的
     利用，在一个16核的服务器上，应该设置 （45/ 25)* 16 = 29 个线程即可。

     假设不是所有的操作都是在平均时间内完成，比如数据库操作，假设是在12~35毫秒区
     间内。即有线程会不断的被某些操作block住，为了充分利用CPU能力，因设置为
     （（35 + 25）/ 25）* 16 = 39个线程。

     所以原则上，如果应用是一个偏重数据库操作的应用，则线程数应高些；如果应用是
     一个高CPU应用，则线程数不用太高。

     假设逻辑处理中，对共享资源的操作用时5毫秒。此时同时只能有一个线程对共享资源
     进行操作，那么在一个16核的服务器上，应该设置 (37 / 5) * 1 = 8 个线程即可。

     假设只有一部分操作对共享资源有写，其他只是读。这样采用乐观锁，使写操作降为
     所有操作的10%，那么有90%的业务，其合适的线程数可为39个线程。10%的业务应为8
     个线程。平均则为 35 + 1 = 36个线程。可见仔细的分析共享资源的使用，能很好的
     提高系统性能。

     根据线程CPU占用率和CPU个数来设置线程数的假设前提是所有线程都要要运行。但实
     际系统中线程处理要处理不同时间达到的请求。

**** 基于网络通讯量的通讯完整性校验的构架。
     NIO构架中不能保证每次READ事件发生时从channel中读出的数据就是完整。例如，在
     通讯数据量较大时，网络层write buffer很容易被写满。此时读到的数据就是不完整
     的。

     从构架角度，应根据应用场景设计三种不同的处理方式。

     基本上有三种类型的应用，
     1. 较低的通信量应用。这类应用的特点是所有的通信量不是很大，而且数据包小。所
        有数据都能在一次网络层buffer flush中全部写出。比如ZooKeeper client对
        cluster的操作。这种通信模式是完全不需要进行数据包校验的。
     2. 基于RPC模式的应用。比如Hadoop，每次NameNode和DataNode之间的通讯都是通过
        RPC框架封装，转变成client对server的调用。所有的操作都是通过Java反射机制
        反射成方法调用，这样操作的特点是每次读到的数据都是可以通过
        ObjectInputStream(new ByteArrayInputStream(bytes)).readObject()操作的。
        这样的应用，应该在第一种应用的架构基础上增加对ObjectInputStream的校验。
        如果校验失败，则说明这次通信没有完成，应和下次read到数据合并在一起处理。
     3. 基于大量数据通信的应用。这种应用的特点是基于一种大数据量通信协议，比如
        RTSP。数据包是否完整需要经过通信协议约定的校验符进行校验。这样就必须实现
        一个校验类。如果校验失败，则说明这次通信没有完成，应和下次read到数据合并
        在一起处理。

* 框架知识
** [[file:spring.org][Spring]]
** ORM框架: mybatis、Hibernate
   最原始的jdbc->Spring的JdbcTemplate->hibernate->JPA->SpringDataJPA的演进之路
** 用spring和ibatis搭建java server
** RPC框架dubbo源码
** NIO框架
*** netty
    REFS:
    - http://blog.csdn.net/king866/article/details/54427447
**** Netty高性能之Reactor线程模型

* 应用服务器
** jboss，https://www.jboss.org/overview/
** tomcat，http://tomcat.apache.org/
   9.1 tomcat的整体架构设计
   9.2 tomcat对通信的并发控制
   9.3 http请求到达tomcat的整个处理流程
** jetty，http://www.eclipse.org/jetty/
** Cookie/Session机制详解
   REFS:
   - http://blog.csdn.net/fangaoxin/article/details/6952954/

   会话（Session）跟踪是Web程序中常用的技术，用来跟踪用户的整个会话。常用的会话
   跟踪技术是Cookie与Session。Cookie通过在客户端记录信息确定用户身份，Session通
   过在服务器端记录信息确定用户身份。

   在程序中，会话跟踪是很重要的事情。理论上，一个用户的所有请求操作都应该属于同
   一个会话，而另一个用户的所有请求操作则应该属于另一个会话，二者不能混淆。

   Web应用程序是使用HTTP协议传输数据的。HTTP协议是无状态的协议。一旦数据交换完毕，
   客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务
   器无法从连接上跟踪会话。
*** Cookie
    要跟踪该会话，必须引入一种机制。Cookie就是这样的一种机制。它可以弥补HTTP协议
    无状态的不足。在Session出现之前，基本上所有的网站都采用Cookie来跟踪会话。

    由于HTTP是一种无状态的协议，服务器单从网络连接上无从知道客户身份。怎么办呢？
    就给客户端们颁发一个通行证吧，每人一个，无论谁访问都必须携带自己通行证。这样
    服务器就能从通行证上确认客户身份了。这就是Cookie的工作原理。Cookie实际上是一
    小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用
    response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览
    器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查
    该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。

    Java中把Cookie封装成了javax.servlet.http.Cookie类。每个Cookie都是该Cookie类的
    对象。服务器通过操作Cookie类对象对客户端Cookie进行操作。通过
    request.getCookie()获取客户端提交的所有Cookie（以Cookie[]数组形式返回），通过
    response.addCookie(Cookiecookie)向客户端设置Cookie。
*** Cookie的不可跨域名性
    很多网站都会使用Cookie。例如，Google会向客户端颁发Cookie，Baidu也会向客户端颁
    发Cookie。那浏览器访问Google会不会也携带上Baidu颁发的Cookie呢？或者Google能不
    能修改Baidu颁发的Cookie呢？答案是否定的。Cookie具有不可跨域名性。根据Cookie规
    范，浏览器访问Google只会携带Google的Cookie，而不会携带Baidu的Cookie。Google也
    只能操作Google的Cookie，而不能操作Baidu的Cookie。Cookie在客户端是由浏览器来管
    理的。浏览器能够保证Google只会操作Google的Cookie而不会操作Baidu的Cookie，从而
    保证用户的隐私安全。浏览器判断一个网站是否能操作另一个网站Cookie的依据是域名。
    Google与Baidu的域名不一样，因此Google不能操作Baidu的Cookie。需要注意的是，虽
    然网站images.google.com与网站www.google.com同属于Google，但是域名不一样，二者
    同样不能互相操作彼此的Cookie。
*** Session
**** 什么是Session
     Session是另一种记录客户状态的机制，不同的是Cookie保存在客户端浏
     览器中，而Session保存在服务器上。客户端浏览器访问服务器的时候，服务器把客户端
     信息以某种形式记录在服务器上。这就是Session。

     Session对应的类为javax.servlet.http.HttpSession类。每个来访者对应一个Session
     对象，所有该客户的状态信息都保存在这个Session对象里。Session对象是在客户端第
     一次请求服务器的时候创建的。Session也是一种key-value的属性对，通过
     getAttribute(Stringkey)和setAttribute(String key，Objectvalue)方法读写客户状
     态信息。

     Session保存在服务器端。为了获得更高的存取速度，服务器一般把Session放在内存里。
     每个用户都会有一个独立的Session。如果Session内容过于复杂，当大量客户访问服务
     器时可能会导致内存溢出。因此，Session里的信息应该尽量精简。Session在用户第一
     次访问服务器的时候自动创建。需要注意只有访问JSP、Servlet等程序时才会创建
     Session，只访问HTML、IMAGE等静态资源并不会创建Session。如果尚未生成Session，
     也可以使用request.getSession(true)强制生成Session。Session生成后，只要用户继
     续访问，服务器就会更新Session的最后访问时间，并维护该Session。用户每访问服务
     器一次，无论是否读写Session，服务器都认为该用户的Session“活跃（active）”了
     一次。

     为防止内存溢出，服务器会把长时间内没有活跃的Session从内存删除。这个时间就是
     Session的超时时间。如果超过了超时时间没访问过服务器，Session就自动失效了。
**** Session对浏览器的要求
     虽然Session保存在服务器，对客户端是透明的，它的正常运行仍然需要客户端浏览器
     的支持。这是因为Session需要使用Cookie作为识别标志。HTTP协议是无状态的，
     Session不能依据HTTP连接来判断是否为同一客户，因此服务器向客户端浏览器发送一
     个名为JSESSIONID的Cookie，它的值为该Session的id（也就是HttpSession.getId()的
     返回值）。Session依据该Cookie来识别是否为同一用户。该Cookie为服务器自动生成
     的，它的maxAge属性一般为–1，表示仅当前浏览器内有效，并且各浏览器窗口间不共享，
     关闭浏览器就会失效。因此同一机器的两个浏览器窗口访问服务器时，会生成两个不同
     的Session。但是由浏览器窗口内的链接、脚本等打开的新窗口（也就是说不是双击桌
     面浏览器图标等打开的窗口）除外。这类子窗口会共享父窗口的Cookie，因此会共享一
     个Session。

     注意：新开的浏览器窗口会生成新的Session，但子窗口除外。子窗口会共用父窗口的
     Session。例如，在链接上右击，在弹出的快捷菜单中选择“在新窗口中打开”时，子
     窗口便可以访问父窗口的Session。如果客户端浏览器将Cookie功能禁用，或者不支持
     Cookie怎么办？例如，绝大多数的手机浏览器都不支持Cookie。Java Web提供了另一种
     解决方案：URL地址重写。

     URL地址重写是对客户端不支持Cookie的解决方案。URL地址重写的原理是将该用户
     Session的id信息重写到URL地址中。服务器能够解析重写后的URL获取Session的id。这
     样即使客户端不支持Cookie，也可以使用Session来记录用户状态。
     HttpServletResponse类提供了encodeURL(Stringurl)实现URL地址重写，

     注意：TOMCAT判断客户端浏览器是否支持Cookie的依据是请求中是否含有Cookie。尽管
     客户端可能会支持Cookie，但是由于第一次请求时不会携带任何Cookie（因为并无任何
     Cookie可以携带），URL地址重写后的地址中仍然会带有jsessionid。当第二次访问时
     服务器已经在浏览器中写入Cookie了，因此URL地址重写后的地址中就不会带有
     jsessionid了。
**** Session中禁止使用Cookie
     既然WAP上大部分的客户浏览器都不支持Cookie，索性禁止Session使用Cookie，统一使
     用URL地址重写会更好一些。Java Web规范支持通过配置的方式禁用Cookie。下面举例
     说一下怎样通过配置禁止使用Cookie。
*** 分布式Session的几种实现方式
    1. 基于数据库的Session共享
    2. 基于NFS共享文件系统
    3. 基于memcached 的session，如何保证 memcached 本身的高可用性？
    4. 基于resin/tomcat web容器本身的session复制机制
    5. 基于TT/Redis 或 jbosscache 进行 session 共享。
    6. 基于cookie 进行session共享

    一、Session Replication 方式管理 (即session复制)
    简介：将一台机器上的Session数据广播复制到集群中其余机器上
    使用场景：机器较少，网络流量较小
    优点：实现简单、配置较少、当网络中有机器Down掉时不影响用户访问
    缺点：广播式复制到其余机器有一定廷时，带来一定网络开销

    二、Session Sticky 方式管理
    简介：即粘性Session、当用户访问集群中某台机器后，强制指定后续所有请求均落到此机器上
    使用场景：机器数适中、对稳定性要求不是非常苛刻
    优点：实现简单、配置方便、没有额外网络开销
    缺点：网络中有机器Down掉时、用户Session会丢失、容易造成单点故障

    三、缓存集中式管理
    简介：将Session存入分布式缓存集群中的某台机器上，当用户访问不同节点时先从缓存中拿Session信息
    使用场景：集群中机器数多、网络环境复杂
    优点：可靠性好
    缺点：实现复杂、稳定性依赖于缓存的稳定性、Session信息放入缓存时要有合理的策略写入

* 数据库
** 关系型数据库
** NoSQL
** [[http://m.blog.csdn.net/wwh578867817/article/details/50493940][为什么 MongoDB （索引）使用B-树而 Mysql 使用 B+树？]]
** JDBC事务
*** 事务的四大特性（ACID）
    事务的四大特性是：
    - 原子性（Atomicity）：事务中所有操作是不可再分割的原子单位。事务中所有操作
      要么全部执行成功，要么全部执行失败。
    - 一致性（Consistency）：事务执行后，数据库状态与其它业务规则保持一致。如转
      账业务，无论事务执行成功与否，参与转账的两个账号余额之和应该是不变的。
    - 隔离性（Isolation）：隔离性是指在并发操作中，不同事务之间应该隔离开来，使
      每个并发中的事务不会相互干扰。
    - 持久性（Durability）：一旦事务提交成功，事务中所有的数据操作都必须被持久化
      到数据库中，即使提交事务后，数据库马上崩溃，在数据库重启时，也必须能保证通
      过某种机制恢复数据。
*** MySQL中的事务
    在默认情况下，mysql每执行一条SQL语句，都是一个单独的事务。如果需要在一个事务
    中包含多条SQL语句，那么需要开启事务和结束事务。
    - 开启事务：starttransaction；
    - 结束事务：commit或rollback。
    在执行SQL语句之前，先执行strat transaction，这就开启了一个事务（事务的起点），
    然后可以去执行多条SQL语句，最后要结束事务，commit表示提交，即事务中的多条SQL
    语句所做出的影响会持久化到数据库中。或者rollback，表示回滚，即回滚到事务的起
    点，之前做的所有操作都被撤消了！
*** JDBC事务
    在jdbc中处理事务，都是通过Connection完成的！

    同一事务中所有的操作，都在使用同一个Connection对象！

    Connection的三个方法与事务相关：
    - setAutoCommit(boolean)：设置是否为自动提交事务，如果true（默认值就是true）
      表示自动提交，也就是每条执行的SQL语句都是一个单独的事务，如果设置false，那
      么就相当于开启了事务了；con.setAutoCommit(false)表示开启事务！
    - commit()：提交结束事务；con.commit();表示提交事务
    - rollback()：回滚结束事务。con.rollback();表示回滚事务
*** 事务隔离级别
    事务的并发读问题
    - 脏读：读取到另一个事务未提交数据；
    - 不可重复读：两次读取不一致；
    - 幻读：读到另一事务已提交数据。

    并发事务问题
    因为并发事务导致的问题大致有5类，其中两类是更新问题，三类是读问题。
    - 脏读（dirty read）：读到另一个事务的未提交更新数据，即读取到了脏数据；
    - 不可重复读（unrepeatable read）：对同一记录的两次读取不一致，因为另一事务对该记录做了修改；
    - 幻读（虚读）（phantom read）：对同一张表的两次查询不一致，因为另一事务插入了一条记录；

    四大隔离级别

    4个等级的事务隔离级别，在相同数据环境下，使用相同的输入，执行相同的工作，根
    据不同的隔离级别，可以导致不同的结果。不同事务隔离级别能够解决的数据并发问题
    的能力是不同的。

    - SERIALIZABLE（串行化）
      - 不会出现任何并发问题，因为它是对同一数据的访问是串行的，非并发访问的；
      - 性能最差；

    - REPEATABLE READ（可重复读）（MySQL）
      - 防止脏读和不可重复读，不能处理幻读问题；
      - 性能比SERIALIZABLE好

    - READ COMMITTED（读已提交数据）（Oracle）
      - 防止脏读，没有处理不可重复读，也没有处理幻读；
      - 性能比REPEATABLE READ好

    - READ UNCOMMITTED（读未提交数据）
      - 可能出现任何事务并发问题
      - 性能最好

* 大数据知识
* 网络安全知识
* JVM
* 试题
  REFS:
  - http://blog.csdn.net/geolo/article/details/8670900
  - http://ifeve.com/15-java-faq/
  - http://ifeve.com/javaconcurrency-interview-questions-combat/

** 如何实现乐观锁（CAS）？如何避免ABA问题？
   1. 读取内存值的方式实现了乐观锁(比如：SVN系统)，方法：第一，比较内存值和期望
      值；第二，替换内存值为要替换值。
   2. 带参数版本来避免aba问题，在读取和替换的时候进行判定版本是否一致
** 读写锁可以用于什么应用场景？
   读写锁可以用于 “多读少写” 的场景，读写锁支持多个读操作并发执行，写操作只能
   由一个线程来操作

   ReadWriteLock对向数据结构相对不频繁地写入，但是有多个任务要经常读取这个数据结
   构的这类情况进行了优化。ReadWriteLock使得你可以同事有多个读取者，只要它们都不
   试图写入即可。如果写锁已经被其他任务持有，那么任何读取者都不能访问，直至这个
   写锁被释放为止。

   ReadWriteLock 对程序心性能的提高受制于如下几个因素也还有其他等等的因素。
   1. 数据被读取的频率与被修改的频率相比较的结果。
   2. 读取和写入的时间
   3. 有多少线程竞争
   4. 是否在多处理机器上运行
** 什么时候应该使用可重入锁？
   重入锁指的是在某一个线程中可以多次获得同一把锁，在线程中多次操作有锁的方法。

** 什么场景下可以使用volatile替换synchronized？
   只需要保证共享资源的可见性的时候可以使用volatile替代，synchronized保证可操作
   的原子性一致性和可见性。volatile适用于新值不依赖于就值的情形。

   volatile是java提供的一种同步手段，只不过它是轻量级的同步，为什么这么说，因为
   volatile只能保证多线程的内存可见性，不能保证多线 程的执行有序性。而最彻底的同
   步要保证有序性和可见性，例如synchronized。任何被volatile修饰的变量，都不拷贝
   副本到工作内存，任何 修改都及时写在主存。因此对于Valatile修饰的变量的修改，所
   有线程马上就能看到，但是volatile不能保证对变量的修改是有序的。volatile存在的
   意义是，任何线程对某个变量的修改，都会马上被其他线程读取到，因为直接操作主存，
   没有线程对工作内存和主存的同步。所以，volatile的使用场景是有限的，在有限的一
   些情形下可以使用 volatile 变量替代锁（synchronized）。

   要使 volatile 变量提供理想的线程安全,必须同时满足下面两个条件:
   1. 对变量的写操作不依赖于当前值。
   2. 该变量没有包含在具有其他变量的不变式中
